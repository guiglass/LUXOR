## APS LUXOR Documentation

<p align="center">
  <a href="/downloads.md">
     <img src="www.mediafire.com/view/jk3i4lnajkp71gj/logo.png/file">
  </a>
</p>

Creators are welcome to join the [APS Discord](https://discord.com/invite/ErZcKaQ) - For tech support, latest updates, tips, ideas, showcasings and sharing community content or speaking with developers.

APS LUXOR is a motion capture tool that was originally developed as a VR training simulator and has quickly evolved into a highly configurable motion capture utility capable of recording or live streaming many types of custom avatars while using simultaneous full body tracking, eye tracking, facial tracking, finger tracking, audio and visemes lipsync, dynamicBone simulation capture and with improved IK solvers and profiles that can be tuned for creating unique or natural motion and expression. Users may also include custom scenes, objs, props and most humanoid avatars are compatible using the APSSDK for generating assets from the very popular Unity Editor. Users may add custom avatars including custom shaders with dynamicBone *physics* components which can also be recorded and exported into Blender along with automation to instantly load entire scene compilations so that artists may begin rendering in minutes. And through much collaboration and hard work with help from many generous community members and contributions offering valuable feedback and wonderful ideas and requests for future features has helped me to aspire to develop a mocap tool designed and tailored for mocap artists and game developers, educators and entertainers or hobbyist who wishes to create quality motion capture content quickly and using only standard consumer VR hardware. LUXOR can be used both live and/or for recording and exporting mocap using custom avatars. LUXOR offers a lot of built in automation to help with exporting entire animated scenes and automatically building them to Blender scenes to begin rendering (even complex) scenes in Blender in minutes. And with recent feature added LUXOR now offers the ability to connect avatars entirely to trackers instead of requiring an HMD, this allows more flexibility so that users may calibrate using a head trackers in place of the HMD.

Here I will try to explain some of the features and techniques for getting started with APS LUXOR as a tool for creating motion capture in VR from custom avatars which then can then be auto-imported into a Blender scene and can be ready for rendering within minutes of recording mocap. Later I will also try to show examples of using LUXOR for live productions such as streaming avatars, live presentations and VTuber community.

- [Frequently Asked Questions](questions.md)
- [Minimum requirements](requirements.md)
- Getting started
- [Downloads Section](downloads.md)
- Recording Mocap
- Exporting Mocap to Blender
- Face Capture with the LUXOR Sidekick IOS app
- [Finger tracking using Quest 2 app](quest%20finger%20tracking.md)
- [Adding Custom Avatars (APS SDK Part 1)](apssdk_part1.md)
- [Adding Custom Props (APS SDK Part 2)](apssdk_part2.md)
- [Adding Custom Worlds (APS SDK Part 3)](apssdk_part3.md)
- [Privacy Policy](https://sites.google.com/view/bravecinema/privacy-policy)

- License

More information on the [Patreon](https://www.patreon.com/prepstudio) about page.
